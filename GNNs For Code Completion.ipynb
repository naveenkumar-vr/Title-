{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import torch_geometric\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GATConv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import random\n",
    "import time\n",
    "from earlystopping import EarlyStopping\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import os, psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RAM():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return (process.memory_info().rss/1024/1024/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('common_Terminals','rb')\n",
    "common_terminals = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('map_terminals_val','rb')\n",
    "map_terminals_val = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('map_terminals_type','rb')\n",
    "map_type = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_terminal(node):\n",
    "    if('children' in node):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "curr_idx = 0\n",
    "map_idx_val = {}\n",
    "\n",
    "\n",
    "def dfs(program, idx, flattened_tree, edge_list, map_right_sibling, map_non_terminal_child):\n",
    "    global curr_idx\n",
    "    global map_idx_val\n",
    "    node = program[idx]\n",
    "    map_idx_val[idx] = curr_idx\n",
    "    curr_idx += 1\n",
    "    edge_list.append(torch.tensor([map_idx_val[idx], map_idx_val[idx]]))\n",
    "    if(non_terminal(node)):\n",
    "        x = non_terminals_mapping[(map_type[node['type']], map_right_sibling[idx], map_non_terminal_child[idx])]\n",
    "        flattened_tree.append([x, map_terminals_val['none']])\n",
    "        for i in node['children']:\n",
    "            dfs(program, i, flattened_tree, edge_list, map_right_sibling, map_non_terminal_child)\n",
    "        for i in node['children']:\n",
    "            edge_list.append(torch.tensor([map_idx_val[idx], map_idx_val[i]]))\n",
    "            edge_list.append(torch.tensor([map_idx_val[i], map_idx_val[idx]]))\n",
    "#             edge_list1.append(map_idx_val[idx])\n",
    "#             edge_list2.append(map_idx_val[i])\n",
    "#             edge_list1.append(map_idx_val[i]) #Bi-directional edges\n",
    "#             edge_list2.append(map_idx_val[idx])\n",
    "            \n",
    "    else:\n",
    "        val = \"\"\n",
    "        if(node['value'] not in map_terminals_val):\n",
    "            val = map_terminals_val['UNK']\n",
    "        else:\n",
    "            val = map_terminals_val[node['value']]\n",
    "        x = non_terminals_mapping[(map_type[node['type']], 0, 0)]\n",
    "        flattened_tree.append([x, val])\n",
    "            \n",
    "\n",
    "def construct_Seq(program):\n",
    "    global curr_idx\n",
    "    global map_idx_val\n",
    "    map_right_sibling = {}\n",
    "    map_non_terminal_child = {}\n",
    "    tokens = []\n",
    "    edge_list = []\n",
    "    flattened_tree = []\n",
    "    map_right_sibling[0] = False\n",
    "    for node in program:\n",
    "        if(non_terminal(node)):\n",
    "            for i in range(len(node['children'])):\n",
    "                if(i + 1 == len(node['children'])):\n",
    "                    map_right_sibling[node['children'][i]] = False\n",
    "                else:\n",
    "                    map_right_sibling[node['children'][i]] = True\n",
    "            non_terminal_child = False\n",
    "            for i in node['children']:\n",
    "                if('children' in program[i]):\n",
    "                    non_terminal_child = True\n",
    "                    break\n",
    "            map_non_terminal_child[node['id']] = non_terminal_child\n",
    "    curr_idx = 0\n",
    "    map_idx_val = {}\n",
    "    dfs(program, 0, flattened_tree, edge_list, map_right_sibling, map_non_terminal_child)\n",
    "    return flattened_tree, edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_terminals_mapping = {}\n",
    "c = 0\n",
    "for i in range(46):\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            non_terminals_mapping[(i, j, k)] = c\n",
    "            c += 1\n",
    "            \n",
    "inverse_mapping = {}\n",
    "for i in non_terminals_mapping:\n",
    "    inverse_mapping[non_terminals_mapping[i]] = i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used is:  1.1315650939941406\n"
     ]
    }
   ],
   "source": [
    "print(\"RAM used is: \", RAM())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genProgramsEval():\n",
    "    with open('programs_eval.json', encoding='latin1') as f:\n",
    "        for line in f:\n",
    "            t = json.loads(line)\n",
    "            t.pop()\n",
    "            last_elem = t[-1]['id']\n",
    "            d = {'id' : last_elem + 1, 'type': \"EOF\", 'value' : \"EOF\"}\n",
    "            t.append(d)\n",
    "            for j in t:\n",
    "                if(\"children\" not in j and \"value\" not in j):\n",
    "                    j['value'] = j['type']\n",
    "            tree, edges = construct_Seq(t)\n",
    "            edges = sorted(edges, key = lambda x : max(x[0], x[1]))\n",
    "            edges = torch.stack(edges, dim = 0)\n",
    "            #print(edges.shape)\n",
    "            #print(tree, edge_list)\n",
    "            tree = torch.tensor(tree, dtype = torch.long)\n",
    "            #train_data.append(tree)\n",
    "            #edge_list.append(edges)\n",
    "            yield tree, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genPrograms():\n",
    "    with open('programs_training.json', encoding='latin1') as f:\n",
    "        for line in f:\n",
    "            t = json.loads(line)\n",
    "            t.pop()\n",
    "            last_elem = t[-1]['id']\n",
    "            d = {'id' : last_elem + 1, 'type': \"EOF\", 'value' : \"EOF\"}\n",
    "            t.append(d)\n",
    "            for j in t:\n",
    "                if(\"children\" not in j and \"value\" not in j):\n",
    "                    j['value'] = j['type']\n",
    "            tree, edges = construct_Seq(t)\n",
    "            edges = sorted(edges, key = lambda x : max(x[0], x[1]))\n",
    "            edges = torch.stack(edges, dim = 0)\n",
    "            #print(edges.shape)\n",
    "            #print(tree, edge_list)\n",
    "            tree = torch.tensor(tree, dtype = torch.long)\n",
    "            #train_data.append(tree)\n",
    "            #edge_list.append(edges)\n",
    "            yield tree, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructTensorfromProgram(data, edges):\n",
    "    #print(edges)\n",
    "    res = torch.split(data, 50)\n",
    "    res = list(res)\n",
    "    edge_list = []\n",
    "    \n",
    "    c = 1\n",
    "    curr_idx = []\n",
    "    i = 0\n",
    "    min_val = 0\n",
    "    while(i < edges.shape[0]):\n",
    "        if(max(edges[i][0], edges[i][1]) >= min_val + 48):\n",
    "            edge_list.append(torch.stack(curr_idx, dim = 0))\n",
    "            curr_idx = []\n",
    "            min_val += 49\n",
    "        else:\n",
    "            while(i < edges.shape[0] and min(edges[i][0], edges[i][1]) <= min_val):\n",
    "                i += 1\n",
    "            if(i < edges.shape[0]):\n",
    "                curr_idx.append(edges[i])\n",
    "        i += 1\n",
    "        \n",
    "    if(len(curr_idx) > 0):\n",
    "        edge_list.append(torch.stack(curr_idx, dim = 0))\n",
    "    \n",
    "    \n",
    "    if(res[-1].shape[0] != 50):\n",
    "        x = non_terminals_mapping[(map_type['EOF'], 0, 0)]\n",
    "        dummy_tensor = torch.tensor([x, map_terminals_val['none']])\n",
    "        dummy_tensor = dummy_tensor.repeat((50 - res[-1].shape[0], 1))\n",
    "        dummy_tensor = torch.cat([res[-1], dummy_tensor])\n",
    "        res = res[:-1]\n",
    "        res.append(dummy_tensor)\n",
    "    res = torch.stack(res, dim = 0)\n",
    "    ans = res[:, 49, :]\n",
    "    res = res[:, :-1, :]\n",
    "    ans[:, 0].apply_(lambda x : inverse_mapping[x])\n",
    "    return res, ans, edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 49\n",
    "NUM_CLASSES_VALUE = len(map_terminals_val) + 1\n",
    "NUM_CLASSES_TYPE = len(non_terminals_mapping) + 1\n",
    "WORD_EMBEDDING_DIM1 = 128\n",
    "WORD_EMBEDDING_DIM2 = 64\n",
    "HIDDEN_SIZE = 512\n",
    "NUM_HEADS = 1\n",
    "\n",
    "\n",
    "class Graph2CodeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Graph2CodeNet, self).__init__()\n",
    "        self.embeddingLayervalue = nn.Embedding(NUM_CLASSES_VALUE, WORD_EMBEDDING_DIM1)\n",
    "        self.embeddingLayertype = nn.Embedding(NUM_CLASSES_TYPE, WORD_EMBEDDING_DIM2)\n",
    "        self.GRU = nn.GRU(input_size =WORD_EMBEDDING_DIM1 + WORD_EMBEDDING_DIM2, hidden_size = HIDDEN_SIZE, \n",
    "                          batch_first = True, num_layers = 2, bidirectional = True)\n",
    "        #self.linearTerminal = nn.Linear(in_features = HIDDEN_SIZE * 4, out_features = 10002)\n",
    "        self.att1 = GATConv(HIDDEN_SIZE * 2, HIDDEN_SIZE * 4, NUM_HEADS)\n",
    "        self.att2 = GATConv(HIDDEN_SIZE * 4, HIDDEN_SIZE * 4, NUM_HEADS)\n",
    "        self.linearNon_Terminal = nn.Linear(in_features = HIDDEN_SIZE * 4, out_features = 46)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x, h_0, edges):\n",
    "        typeEmbedded = self.embeddingLayertype(x[:,:,0])\n",
    "        valEmbedded = self.embeddingLayervalue(x[:,:,1])\n",
    "        x = torch.cat((typeEmbedded, valEmbedded), 2)\n",
    "        h_seq, h_n = self.GRU(x, h_0)\n",
    "        h_seq = h_seq.view(49, -1)\n",
    "        edges = edges.t().contiguous()\n",
    "        #print(edges)\n",
    "        h_seq = self.att1(h_seq, edges)\n",
    "        h_seq = self.att2(h_seq, edges)\n",
    "        #HERE ONWARDS\n",
    "        h_out = h_seq[-1, :].view(1, -1)\n",
    "        out = self.linearNon_Terminal(h_out)\n",
    "        #print(out.shape)\n",
    "        #print(h_out.shape, h_0.shape)\n",
    "        return out, h_out.view(4, 1, 512)\n",
    "    \n",
    "    \n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Graph2CodeNet()\n",
    "#device = torch.device('cuda:0')\n",
    "#model = model.to(device)\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#   # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "#     model = nn.DataParallel(model)\n",
    "\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!shuf programs_training.json -o shuffled_programs_training.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_losses = 0\n",
    "avg_train_losses = []\n",
    "\n",
    "start = time.time()\n",
    "count = 0\n",
    "idx = 0\n",
    "\n",
    "for train_data, edge_list in genPrograms():\n",
    "    h_0 = torch.zeros(4, 1, 512)\n",
    "    h_0 = h_0.to(device)\n",
    "    res, ans, edges = constructTensorfromProgram(train_data, edge_list)\n",
    "    for j in range(res.shape[0]):\n",
    "        x = res[j, :,:].view(1, 49, -1)\n",
    "        x = x.to(device)\n",
    "        #print(idx, j)\n",
    "        edge = edges[j]\n",
    "        edge = edge.to(device)\n",
    "        out_N, h_0 = model(x, h_0, torch.sub(edge, other = 49, alpha = j))\n",
    "        count += 1       \n",
    "        ans1 = ans[j, 0:1]\n",
    "        ans1 = ans1.to(device)\n",
    "        loss = criterion(out_N, ans1) #ANS IS TO BE PROCESSED\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_value_(model.parameters(), clip_value = 5.0)\n",
    "        train_losses += loss.item()\n",
    "        if(count % BATCH_SIZE == 0):\n",
    "            avg_train_losses.append(train_losses / BATCH_SIZE)\n",
    "            train_losses = 0\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        h_0 = h_0.detach()\n",
    "        #print(j)\n",
    "        if(j >= 100):\n",
    "            break\n",
    "    #print(idx)\n",
    "    if(idx == 20000):\n",
    "        break\n",
    "    if(idx % 1000 == 0):\n",
    "        print(f\"Train time is: {(time.time() - start)/60} -> {idx*100 / 20000}%\")\n",
    "    idx += 1\n",
    "        \n",
    "plt.plot(avg_train_losses)\n",
    "end = time.time()\n",
    "print(\"Time taken:\", (end - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './GNN3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a previous ran model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Graph2CodeNet()\n",
    "model.load_state_dict(torch.load('./GNN2', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph2CodeNet(\n",
      "  (embeddingLayervalue): Embedding(10002, 128)\n",
      "  (embeddingLayertype): Embedding(185, 64)\n",
      "  (GRU): GRU(192, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (att1): GATConv(1024, 2048, heads=1)\n",
      "  (att2): GATConv(2048, 2048, heads=1)\n",
      "  (linearNon_Terminal): Linear(in_features=2048, out_features=46, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set prediction acccuracy is: 74.03%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    idx = 0\n",
    "    correct = 0\n",
    "    for train_data, edge_list in genProgramsEval():\n",
    "        h_0 = torch.zeros(4, 1, 512)\n",
    "        h_0 = h_0.to(device)\n",
    "        res, ans, edges = constructTensorfromProgram(train_data, edge_list)\n",
    "        for j in range(res.shape[0]):\n",
    "            x = res[j, :,:].view(1, 49, -1)\n",
    "            x = x.to(device)\n",
    "            #print(idx, j)\n",
    "            edge = edges[j]\n",
    "            edge = edge.to(device)\n",
    "            out_N, h_0 = model(x, h_0, torch.sub(edge, other = 49, alpha = j))\n",
    "            total += 1       \n",
    "            ans1 = ans[j, 0:1]\n",
    "            ans1 = ans1.to(device)\n",
    "            out_N = torch.argmax(out_N, dim = 1) #ANS IS TO BE PROCESSED\n",
    "            correct += sum(out_N == ans1).item()\n",
    "            if(total >= 10000):\n",
    "                break\n",
    "        if(total >= 10000):\n",
    "            break\n",
    "        idx += 1\n",
    "\n",
    "    print(f\"Validation set prediction acccuracy is: {100*correct/total}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
